{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoder with vgg19 (MNSIT).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buldubu/AutoEncoder/blob/master/AutoEncoder_with_vgg19_(MNSIT).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_J6F9UGEfCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.tensor import *\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYWqoTNnO1-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "import warnings\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import torch\n",
        "import codecs\n",
        "from torchvision.datasets.utils import download_url, download_and_extract_archive, extract_archive, \\\n",
        "    makedir_exist_ok, verify_str_arg\n",
        "\n",
        "\n",
        "\n",
        "class MNIST(VisionDataset):\n",
        "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory of dataset where ``MNIST/processed/training.pt``\n",
        "            and  ``MNIST/processed/test.pt`` exist.\n",
        "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
        "            otherwise from ``test.pt``.\n",
        "        download (bool, optional): If true, downloads the dataset from the internet and\n",
        "            puts it in root directory. If dataset is already downloaded, it is not\n",
        "            downloaded again.\n",
        "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
        "        target_transform (callable, optional): A function/transform that takes in the\n",
        "            target and transforms it.\n",
        "    \"\"\"\n",
        "\n",
        "    resources = [\n",
        "        (\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", \"f68b3c2dcbeaaa9fbdd348bbdeb94873\"),\n",
        "        (\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\", \"d53e105ee54ea40749a09fcbcd1e9432\"),\n",
        "        (\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", \"9fb629c4189551a2d022fa330f9573f3\"),\n",
        "        (\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\", \"ec29112dd5afa0611ce80d1b7f02629c\")\n",
        "    ]\n",
        "\n",
        "    training_file = 'training.pt'\n",
        "    test_file = 'test.pt'\n",
        "    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
        "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
        "\n",
        "    @property\n",
        "    def train_labels(self):\n",
        "        warnings.warn(\"train_labels has been renamed targets\")\n",
        "        return self.targets\n",
        "\n",
        "    @property\n",
        "    def test_labels(self):\n",
        "        warnings.warn(\"test_labels has been renamed targets\")\n",
        "        return self.targets\n",
        "\n",
        "    @property\n",
        "    def train_data(self):\n",
        "        warnings.warn(\"train_data has been renamed data\")\n",
        "        return self.data\n",
        "\n",
        "    @property\n",
        "    def test_data(self):\n",
        "        warnings.warn(\"test_data has been renamed data\")\n",
        "        return self.data\n",
        "\n",
        "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        super(MNIST, self).__init__(root, transform=transform,\n",
        "                                    target_transform=target_transform)\n",
        "        self.train = train  # training set or test set\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not self._check_exists():\n",
        "            raise RuntimeError('Dataset not found.' +\n",
        "                               ' You can use download=True to download it')\n",
        "\n",
        "        if self.train:\n",
        "            data_file = self.training_file\n",
        "        else:\n",
        "            data_file = self.test_file\n",
        "        self.data, self.targets = torch.load(os.path.join(self.processed_folder, data_file))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], int(self.targets[index])\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img.numpy(), mode='L')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    @property\n",
        "    def raw_folder(self):\n",
        "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
        "\n",
        "    @property\n",
        "    def processed_folder(self):\n",
        "        return os.path.join(self.root, self.__class__.__name__, 'processed')\n",
        "\n",
        "    @property\n",
        "    def class_to_idx(self):\n",
        "        return {_class: i for i, _class in enumerate(self.classes)}\n",
        "\n",
        "    def _check_exists(self):\n",
        "        return (os.path.exists(os.path.join(self.processed_folder,\n",
        "                                            self.training_file)) and\n",
        "                os.path.exists(os.path.join(self.processed_folder,\n",
        "                                            self.test_file)))\n",
        "\n",
        "    def download(self):\n",
        "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
        "\n",
        "        if self._check_exists():\n",
        "            return\n",
        "\n",
        "        makedir_exist_ok(self.raw_folder)\n",
        "        makedir_exist_ok(self.processed_folder)\n",
        "\n",
        "        # download files\n",
        "        for url, md5 in self.resources:\n",
        "            filename = url.rpartition('/')[2]\n",
        "            download_and_extract_archive(url, download_root=self.raw_folder, filename=filename, md5=md5)\n",
        "\n",
        "        # process and save as torch files\n",
        "        print('Processing...')\n",
        "\n",
        "        training_set = (\n",
        "            read_image_file(os.path.join(self.raw_folder, 'train-images-idx3-ubyte')),\n",
        "            read_label_file(os.path.join(self.raw_folder, 'train-labels-idx1-ubyte'))\n",
        "        )\n",
        "        test_set = (\n",
        "            read_image_file(os.path.join(self.raw_folder, 't10k-images-idx3-ubyte')),\n",
        "            read_label_file(os.path.join(self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
        "        )\n",
        "        with open(os.path.join(self.processed_folder, self.training_file), 'wb') as f:\n",
        "            torch.save(training_set, f)\n",
        "        with open(os.path.join(self.processed_folder, self.test_file), 'wb') as f:\n",
        "            torch.save(test_set, f)\n",
        "\n",
        "        print('Done!')\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyLTrX26HAhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, init_weights=True):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        \n",
        "        self.conva1 = nn.Conv2d(3,64,3, padding=1)\n",
        "        self.conva2 = nn.Conv2d(64,64,3, padding=1)\n",
        "        self.poola = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "\n",
        "        self.convb1 = nn.Conv2d(64,128,3, padding=1)\n",
        "        self.convb2 = nn.Conv2d(128,128,3, padding=1)\n",
        "        self.poolb = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "\n",
        "        self.convc1 = nn.Conv2d(128,256,3, padding=1)\n",
        "        self.convc2 = nn.Conv2d(256,256,3, padding=1)\n",
        "        self.convc3 = nn.Conv2d(256,256,3, padding=1)\n",
        "        self.convc4 = nn.Conv2d(256,256,3, padding=1)\n",
        "        self.poolc = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "\n",
        "        self.convd1 = nn.Conv2d(256,512,3, padding=1)\n",
        "        self.convd2 = nn.Conv2d(512,512,3, padding=1)\n",
        "        self.convd3 = nn.Conv2d(512,512,3, padding=1)\n",
        "        self.convd4 = nn.Conv2d(512,512,3, padding=1)\n",
        "        self.poold = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "        \n",
        "        self.conve1 = nn.Conv2d(512,512,3, padding=1)\n",
        "        self.conve2 = nn.Conv2d(512,512,3, padding=1)\n",
        "        self.conve3 = nn.Conv2d(512,512,3, padding=1)\n",
        "        self.conve4 = nn.Conv2d(512,512,3, padding=1)\n",
        "        self.poole = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 512 * 7 * 7),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "        )\n",
        "        \n",
        "        self.convTa1 = nn.ConvTranspose2d(64,3,3, padding=1)\n",
        "        self.convTa2 = nn.ConvTranspose2d(64,64,3, padding=1)\n",
        "        self.unpoola = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.convTb1 = nn.ConvTranspose2d(128,64,3, padding=1)\n",
        "        self.convTb2 = nn.ConvTranspose2d(128,128,3, padding=1)\n",
        "        self.unpoolb = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.convTc1 = nn.ConvTranspose2d(256,128,3, padding=1)\n",
        "        self.convTc2 = nn.ConvTranspose2d(256,256,3, padding=1)\n",
        "        self.convTc3 = nn.ConvTranspose2d(256,256,3, padding=1)\n",
        "        self.convTc4 = nn.ConvTranspose2d(256,256,3, padding=1)\n",
        "        self.unpoolc = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.convTd1 = nn.ConvTranspose2d(512,256,3, padding=1)\n",
        "        self.convTd2 = nn.ConvTranspose2d(512,512,3, padding=1)\n",
        "        self.convTd3 = nn.ConvTranspose2d(512,512,3, padding=1)\n",
        "        self.convTd4 = nn.ConvTranspose2d(512,512,3, padding=1)\n",
        "        self.unpoold = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.convTe1 = nn.ConvTranspose2d(512,512,3, padding=1)\n",
        "        self.convTe2 = nn.ConvTranspose2d(512,512,3, padding=1)\n",
        "        self.convTe3 = nn.ConvTranspose2d(512,512,3, padding=1)\n",
        "        self.convTe4 = nn.ConvTranspose2d(512,512,3, padding=1)\n",
        "        self.unpoole = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conva1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conva2(x)\n",
        "        x = F.relu(x)\n",
        "        x, inda = self.poola(x)\n",
        "        \n",
        "        x = self.convb1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convb2(x)\n",
        "        x = F.relu(x)\n",
        "        x, indb = self.poolb(x)\n",
        "\n",
        "        x = self.convc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convc3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convc4(x)\n",
        "        x = F.relu(x)\n",
        "        x, indc = self.poolc(x)\n",
        "        \n",
        "        x = self.convd1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convd2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convd3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convd4(x)\n",
        "        x = F.relu(x)\n",
        "        x, indd = self.poold(x)\n",
        "        \n",
        "        x = self.conve1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conve2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conve3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conve4(x)\n",
        "        x = F.relu(x)\n",
        "        x, inde = self.poole(x)\n",
        "        \n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.linear(x)\n",
        "        x = x.view(-1,512,7,7)\n",
        "        \n",
        "        x = self.unpoole(x, inde)\n",
        "        x = self.convTe4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTe3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTe2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTe1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpoold(x, indd)\n",
        "        x = self.convTd4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTd3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTd2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTd1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpoolc(x, indc)\n",
        "        x = self.convTc4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTc3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTc1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpoolb(x, indb)\n",
        "        x = self.convTb2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTb1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpoola(x, inda)\n",
        "        x = self.convTa2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.convTa1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZGXnvuoQGBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = AutoEncoder().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02xJI3pvQPyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws-cLHP3SpSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.Resize(224),\n",
        "     transforms.Grayscale(num_output_channels=3),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=2,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2KXfdkQVDQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2vwfWCjzojm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        print(inputs, labels)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 49:    # print every 50 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 50))\n",
        "            running_loss = 0.0\n",
        "\n",
        "            dataiter = iter(testloader)\n",
        "            test, adsf = dataiter.next()\n",
        "            imshow(torchvision.utils.make_grid(test))\n",
        "            test = test.cuda()\n",
        "            ouuu = model(test)\n",
        "\n",
        "            # print images\n",
        "            imshow(torchvision.utils.make_grid(ouuu.detach().cpu()))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}